{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def represent(img_path, model_name = 'VGG-Face', model = None, enforce_detection = True, detector_backend = 'opencv', align = True, normalization = 'base'):\n",
    "\n",
    "\t\"\"\"\n",
    "\tThis function represents facial images as vectors.\n",
    "\tParameters:\n",
    "\t\timg_path: exact image path, numpy array or based64 encoded images could be passed.\n",
    "\t\tmodel_name (string): VGG-Face, Facenet, OpenFace, DeepFace, DeepID, Dlib, ArcFace.\n",
    "\t\tmodel: Built deepface model. A face recognition model is built every call of verify function. You can pass pre-built face recognition model optionally if you will call verify function several times. Consider to pass model if you are going to call represent function in a for loop.\n",
    "\t\t\tmodel = DeepFace.build_model('VGG-Face')\n",
    "\t\tenforce_detection (boolean): If any face could not be detected in an image, then verify function will return exception. Set this to False not to have this exception. This might be convenient for low resolution images.\n",
    "\t\tdetector_backend (string): set face detector backend as retinaface, mtcnn, opencv, ssd or dlib\n",
    "\t\tnormalization (string): normalize the input image before feeding to model\n",
    "\tReturns:\n",
    "\t\tRepresent function returns a multidimensional vector. The number of dimensions is changing based on the reference model. E.g. FaceNet returns 128 dimensional vector; VGG-Face returns 2622 dimensional vector.\n",
    "\t\"\"\"\n",
    "\n",
    "\tif model is None:\n",
    "\t\tmodel = build_model(model_name)\n",
    "\n",
    "\t#---------------------------------\n",
    "\n",
    "\t#decide input shape\n",
    "\tinput_shape_x, input_shape_y = functions.find_input_shape(model)\n",
    "\n",
    "\t#detect and align\n",
    "\timg = functions.preprocess_face(img = img_path\n",
    "\t\t, target_size=(input_shape_y, input_shape_x)\n",
    "\t\t, enforce_detection = enforce_detection\n",
    "\t\t, detector_backend = detector_backend\n",
    "\t\t, align = align)\n",
    "\n",
    "\t#---------------------------------\n",
    "\t#custom normalization\n",
    "\n",
    "\timg = functions.normalize_input(img = img, normalization = normalization)\n",
    "\n",
    "\t#---------------------------------\n",
    "\n",
    "\t#represent\n",
    "\tembedding = model.predict(img)[0].tolist()\n",
    "\n",
    "\treturn embedding"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
